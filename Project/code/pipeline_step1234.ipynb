{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StDek\n",
    "\n",
    "added dendograme\n",
    "\n",
    "changed the df.to_numeric code to one line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%html\n",
    "<style>\n",
    "li{\n",
    "  margin: 10px 0;\n",
    "}\n",
    "</style>\n",
    "<h2>EDA Analysis Pipeline</h2>\n",
    "Authors: Stephan, Yijoon, Hans, Frank\n",
    "\n",
    "<h3>Index</h3>\n",
    "<ol type=\"I\">\n",
    "<li><a href='#H1'>Defining the goal/problem</a></li>  \n",
    "<li><a href='#H2'>Fetching and data sanitation</a></li>  \n",
    "<li><a href='#section3'>Understand and visualize the data</a></li>\n",
    "<li><a href='#section4'>Analyze the data</a></li>\n",
    "<li><a href='#section5'>Interpret results</a></li>\n",
    "<li><a href='#section6'>Iterate and refine</a></li>\n",
    "<li><a href='#section7'>Save the data of your analysis</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='H1'></a>\n",
    "## 1. Defining the goal/problem\n",
    "```What is the purpose of this analysis?  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a model that accurately can predict the lifespan based on features in the data and use that to determine the premium for life insurance in an ethical way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all libraries required for the entire EDA\n",
    "\n",
    "from requests import get\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Samuel Norman \"Sam\" Seaborn is a fictional character portrayed by Rob Lowe on the television serial drama The West Wing. Hence: sns\n",
    "from seaborn_qqplot import pplot\n",
    "import pandas as pd\n",
    "\n",
    "import datetime as dt\n",
    "from scipy import stats\n",
    "from sklearn import linear_model \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='H2'></a>\n",
    "## 2. Fetching and data sanitation\n",
    "```\n",
    "- a. collect the data \n",
    "- b. check for: errors, missing values(Nan), data types(object,float,int), duplicates and other inconsistencies\n",
    "- c. clean the data: remove duplicates and remove irrelevant information/columns\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for collecting data in csv form:\n",
    "## ... WIP something to select the file you want to use. \n",
    "\n",
    "df_raw= pd.read_csv('../data/input_data/data.csv',skipinitialspace=True)\n",
    "\n",
    "print(df_raw.head())\n",
    "print()\n",
    "print(df_raw.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for collecting data from REST API\n",
    "\n",
    "# # Make request to an URL\n",
    "# response = requests.get('http://localhost:8080/medish_centrum_randstad/api/netlify?page=1')\n",
    "\n",
    "# file_contents= response.json()  #dictionary\n",
    "# print(type(file_contents))\n",
    "# print(len(file_contents))\n",
    "\n",
    "# df = pd.DataFrame.from_dict(file_contents['data']) #all the needed info was condensed into one data column called 'data'\n",
    "# display(df.head())\n",
    "# display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... select value to be looked at.\n",
    "\n",
    "key = df.keys()\n",
    "\n",
    "pipe = input('please type the name of the column you want to look at')\n",
    "if pipe in key:\n",
    "    print (f'We will be looking at \"{pipe}\" this time.')\n",
    "else:\n",
    "    print ('Please rerun this field and suply a valid column key.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ... get a loc  not used atm\n",
    "# dx=df.columns.get_loc(pipe)\n",
    "# print (dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... removes turns non-int/non-flo to NaN and removes NaN\n",
    "# ... selects if the columns have object as dtype. \n",
    "# ... Then chance the values in the columns to numbers and coerce tot NaN if the value cant be turned into a number. \n",
    "\n",
    "# the df will be the old df where we apply changed with a lambda to apply pd.to_numeric where non numbers will be coerced to NaN for those columns were dtype is object.  \n",
    "df = df.apply(lambda x: pd.to_numeric(x, errors='coerce') if x.dtype == 'object' else x)\n",
    "\n",
    "# ... change the dtype to float 64\n",
    "df.astype('float64').dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplication Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... a check to see if there are duplicates in the data.\n",
    "# ... print the shape of the df\n",
    "# ... report the duplicates and ask if you want the duplicates to be deleted. \n",
    "\n",
    "duplicate_rows_df = df[df.duplicated()]\n",
    "print (\"Number of duplicate rows: \", duplicate_rows_df.shape)\n",
    "\n",
    "if duplicate_rows_df.shape == (0, 8):\n",
    "    print ('There are no unexcpected duplicates')\n",
    "else:\n",
    "    print ('There are unexcpected duplicates please look at the data')\n",
    "    print(duplicate_rows_df)\n",
    "    x=input('Do you want to delete the duplicates? Y/n') \n",
    "    if x == 'Y':\n",
    "        df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #...why is it missing, is it random? : input (impute) or delete? (some decisions come later outlier analysis, but some can be taken now)\n",
    "# # ... future make a selector to remove NaN\n",
    "\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "print(df.head())\n",
    "print ()\n",
    "print (df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for special characters ??/>, delete and convert to int/float etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section3'></a>\n",
    "## 3. Understand and visualize the data\n",
    "```\n",
    "- a. Examine structure and content: size,shape and type of variables\n",
    "- b. Theres great value of simply looking at the data: interquartile range, mean, median etc.\n",
    "- c. Visualize the data with plots: histograms, box plots, scatter plots and heatmaps\n",
    "- d. Identify any outliers, patterns, relationships or trends\n",
    "- e. Decide to impute or delete the outliers\n",
    "- f. Identify new features\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)\n",
    "print(df.describe()) #mean,sd, min,max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick Overall Graphical Overview (!warning, takes ~2min or more)\n",
    "#g = sns.PairGrid(df)\n",
    "#g.map(sns.lineplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak een raster voor 4 images\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, sharey=False, figsize=(18,15))\n",
    "\n",
    "sns.boxplot(x=df[pipe], ax=axs[0,1])\n",
    "\n",
    "axs[1][1].scatter(df[pipe], df['lifespan'])\n",
    "axs[1][1].set_xlabel(pipe)\n",
    "axs[1][1].set_ylabel('lifespan')\n",
    "\n",
    "sns.lineplot(x=df[pipe],y=df['lifespan'], ax=axs[1,0])\n",
    "\n",
    "sns.histplot(data=df,x=pipe, ax=axs[0,0])\n",
    "sns.catplot(data=df, x=pipe, y='lifespan', kind='box', ax=axs[1,1])\n",
    "\n",
    "\n",
    "#jointplot with distribution and regression line\n",
    "sns.jointplot(data=df, x=pipe, y=\"lifespan\",marginal_kws=dict(bins=35), kind='reg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[Correlation Coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)__\n",
    "\n",
    "$ \\rho_{x,y} = \\frac{cov(x,y)}{\\sigma_{x}\\sigma{y}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colorfull matrix, showing correlations\n",
    "df_corr = df.dropna().corr()\n",
    "df_corr.style.background_gradient(cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphical correlation matrix view\n",
    "sns.heatmap(df_corr,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers: impute or delete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show stripplot, boxplot \n",
    "fig, axes = plt.subplots(1,2,figsize=(15,5))\n",
    "sns.stripplot(df, x=pipe, y='lifespan',size=2, color=\".6\",ax=axes[0])\n",
    "sns.boxplot(df[[pipe]],ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=df[pipe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1=df['exercise'].quantile(0.25)\n",
    "#print(\"Q1:\", Q1)\n",
    "#Q3=df['exercise'].quantile(0.75)\n",
    "#print(\"Q3:\", Q3)\n",
    "#IQR=Q3-Q1\n",
    "#print(\"IQR: \", IQR)\n",
    "#lower_bound = Q1 - 1.5*IQR\n",
    "#print(\"Lower Bound:\", lower_bound)\n",
    "#upper_bound = Q3 + 1.5*IQR\n",
    "#print(\"Upper Bound:\", upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean = df[(df['exercise']>lower_bound)&(df['exercise']<upper_bound)]\n",
    "#sns.boxplot(y = df_clean['exercise'])\n",
    "\n",
    "# * Clean up outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From boxplot we can check the outliers. I tried 2 ways to remove the outliers. One way is using IQR. The ohter way is using DBSCAN cluster. According to correlation gradient there were no differences in correlation.  Therefore outliers does not make any difference. I decided to keep the outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN, which stands for density-based spatial clustering of applications with noise, is an unsupervised clustering algorithm. This approach identifies any points that are loosely packed or sit alone outside of densely packed clusters as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[[pipe,'lifespan']]\n",
    "model = DBSCAN()\n",
    "model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = model.labels_\n",
    "plt.scatter(df[pipe], df[\"lifespan\"], c = cluster_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = cluster_labels\n",
    "df_cluster_clean = df[df['labels'] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clean up outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lifespan is highly correlated to exercise. IQR method and DBSCAN cluster method showed same result.\n",
    "Therefore we will remove outliers for a variabel,'exercise'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, y= 'lifespan', x=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New features:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Feature BMI (kg/m^2)\n",
    "# df['bmi'] = df['mass']/(df['length']/100)**2\n",
    "# df.head()\n",
    "\n",
    "# bmi_cats = [0, 18.5, 25, np.inf]\n",
    "# labels_bmi_cats=['underweight','normal_range','overweight']\n",
    "# df['bmi_cat']= pd.cut(df['bmi'], bins=bmi_cats, labels=labels_bmi_cats)\n",
    "\n",
    "# bmi_subcats = [0, 16, 17, 18.5, 25, 30, 35, 40, np.inf]\n",
    "# labels_bmi_subcats=['severe_thinness','moderate_thinness','mild_thinness','normal', 'pre_obese', 'obese_class_I', 'obese_class_II', 'obese_class_III']\n",
    "# df['bmi_subcat']= pd.cut(df['bmi'], bins=bmi_subcats, labels=labels_bmi_subcats)\n",
    "\n",
    "\n",
    "# df.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section4'></a>\n",
    "## 4. Analyze the data\n",
    "```\n",
    "- a. Apply statistical analysis tools: mean, median, mode, standard deviation\n",
    "- b. Go through Checklist for linear regression: normal distribution, continuous variable, correlation and p-value\n",
    "- c  Apply regression\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Calculate P-values</li>\n",
    "\n",
    "If p<0.05 (almost 0) the correlation for the feature is extremely likely to happen again if we collect more sample data and thus representative for the entire set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,p = stats.pearsonr(df.lifespan,df[pipe])\n",
    "print(f'{pipe} corr:',round(r,4))\n",
    "print(f'{pipe} p-val:',round(p,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show Q-Q plot and draw conclusion on linearity and if linear regression is applicable \n",
    "from seaborn_qqplot import pplot\n",
    "myplot = pplot(df, x=\"lifespan\", y=pipe, kind='qq', height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the feature satisfies: \n",
    " - continuous variable\n",
    " - correlation and it is linear-ish\n",
    " - normal-ish distributed \n",
    " We can try to apply a linear regression method <br>\n",
    "( e.g. in the form of\n",
    " $ y=\\alpha*x_{smoking}+\\beta*x_{exercise}+c $ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "X = train[[pipe, 'exercise']]\n",
    "y = train.lifespan\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "print(f'c would be:',regr.predict([[0,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regression, the $R^{2}$ coefficient of determination is a statistical measure of how well the regression predictions approximate the real data points.  <br>\n",
    "Close to 1 means there is a strong correlation between the independent variables smoking, exercise and the dependent variable lifespan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape, test.shape)\n",
    "score = regr.score(test[[pipe, 'exercise']],test.lifespan)\n",
    "print(f'coefficient of determination(R\\N{SUPERSCRIPT TWO}):', score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This might need moving\n",
    "```\n",
    "- Use a dendograme to see if there are obvious clusters that need closer examining.  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(f\"{pipe} Dendrogram\")\n",
    "\n",
    "# Selecting lifespan to be compared with the pipe\n",
    "selected_data = df.loc[:, ['lifespan',pipe]]\n",
    "clusters = shc.linkage(selected_data, \n",
    "            method='ward', \n",
    "            metric=\"euclidean\")\n",
    "shc.dendrogram(Z=clusters)\n",
    "\n",
    "# draw the line to make the picture clearer. Changing the value on the y axis can increase insight.\n",
    "plt.axhline(y=65, color='r', linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section5'></a>\n",
    "## 5. Interpret the results\n",
    "```\n",
    "- Draw conclusions, make insights and communicate in a clear, concise and unbiased manner\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section6'></a>\n",
    "## 6. Iterate and refine\n",
    "```\n",
    "- Explore alternative approaches e.g. test assumptions and update your conclusions based on feedback and new insights \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section7'></a>\n",
    "## 7. Save the data of your analysis\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe the data from this notebook as a csv in the folder output \n",
    "\n",
    "df.to_csv('../data/output_data/data_{}_{}.csv'.format(pipe,dt.datetime.now().strftime(\"%Y-%m-%d %H-%M\")), index=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
